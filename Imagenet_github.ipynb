{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imagenet_github.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WnSUa5ooH_1L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import copy\n",
        "import skimage.io \n",
        "import skimage.segmentation\n",
        "import copy\n",
        "import sklearn\n",
        "import sklearn.metrics\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "import sys\n",
        "import torch.optim as optim\n",
        "import cv2, os, math\n",
        "from PIL import Image\n",
        "import requests\n",
        "import ast\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from itertools import product\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ansariminhaj/ULIME.git"
      ],
      "metadata": {
        "id": "gt15pn-bPdKI",
        "outputId": "f19974f9-57af-4524-de09-5e98f3936151",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ULIME'...\n",
            "remote: Enumerating objects: 158, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (152/152), done.\u001b[K\n",
            "remote: Total 158 (delta 46), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (158/158), 40.21 MiB | 12.19 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Black box model to explain\n",
        "model = torchvision.models.inception_v3(pretrained=True) #Load pretrained model\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "MW44fjCHIJUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "id": "Kc9Z9bkjQafd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage\n",
        "print(skimage.__version__)"
      ],
      "metadata": {
        "id": "RCTBJcd_Qnug",
        "outputId": "c45a48d6-8668-4e4e-f2c2-133606675dde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QsoxPqDMQzE-",
        "outputId": "fe088a15-98cb-49f3-e37c-3e5ff4c7693d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip u/lime_org_U.zip -d v"
      ],
      "metadata": {
        "id": "FU7MgrzCQ-Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install lime (Please Install lime before importing this library)\n",
        "from v.lime_org_U.lime import lime_image\n",
        "#from lime_org_l2.lime import lime_image (Restart kernel before importing so that cache is empty)\n",
        "#from lime_org_cosine.lime import lime_image (Restart kernel before importing so that cache is empty)"
      ],
      "metadata": {
        "id": "p2rBI6GpILLH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def heatmap_image(img,c_list,segments):\n",
        "    num_superpixels = np.unique(segments).shape[0]\n",
        "    mask = np.zeros(segments.shape)\n",
        "    for i in range(num_superpixels):\n",
        "        mask[segments == i] = c_list[i] \n",
        "    return mask\n",
        "\n",
        "def get_image(path):\n",
        "  with open(os.path.abspath(path), 'rb') as f:\n",
        "      with Image.open(f) as img:\n",
        "          return img.convert('RGB') \n",
        "        \n",
        "# resize and take the center part of image to what our model expects\n",
        "def get_input_transform():\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                    std=[0.229, 0.224, 0.225])       \n",
        "    transf = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ])    \n",
        "\n",
        "    return transf\n",
        "\n",
        "def get_input_tensors(img):\n",
        "    transf = get_input_transform()\n",
        "    # unsqeeze converts single image to batch of 1\n",
        "    return transf(img).unsqueeze(0)\n",
        "\n",
        "def get_pil_transform(): \n",
        "    transf = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.CenterCrop(224)\n",
        "    ])    \n",
        "\n",
        "    return transf\n",
        "\n",
        "def get_preprocess_transform():\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                    std=[0.229, 0.224, 0.225])     \n",
        "    transf = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ])    \n",
        "\n",
        "    return transf    \n",
        "\n",
        "pill_transf = get_pil_transform()\n",
        "preprocess_transform = get_preprocess_transform()\n",
        "\n",
        "def batch_predict(images):\n",
        "    model.eval()\n",
        "    batch = torch.stack(tuple(preprocess_transform(i) for i in images), dim=0)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    batch = batch.to(device)\n",
        "    \n",
        "    logits = model(batch)\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    return probs.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "perturbations_num = [10, 50, 100, 200, 300, 500, 700, 1000, 1500, 2000, 2500, 3000]\n",
        "\n",
        "explainer = lime_image.LimeImageExplainer(feature_selection='none')\n",
        "\n",
        "data_labels_folder = \"pert_labels\" #This folder contains perturbations (data.txt) + corresponding labels (labels.txt) for the first 10 classes. We fix them once and use for all three variants (L2, Cosine and ULIME).\n",
        "\n",
        "#For generating your own perturbations and labels, follow the steps below: \n",
        "\n",
        "#UNCOMMENT these lines in lime_image.py: \n",
        "\n",
        "#data, labels = self.data_labels(image, fudged_image, segments,\n",
        "#                                classifier_fn, num_samples,\n",
        "#                                batch_size=batch_size,\n",
        "#                                progress_bar=progress_bar)\n",
        "\n",
        "#COMMENT these lines in lime_image.py:\n",
        "\n",
        "#data = data_fixed\n",
        "#labels = labels_fixed\n",
        "\n",
        "#UNCOMMENT #[:, label] in this line in lime_base.py:\n",
        "\n",
        "#labels_column = neighborhood_labels#[:, label]\n",
        "\n",
        "lime_base.py\n",
        "folder_name = \"imagenet_ulime\"\n",
        "runs = 10\n",
        "\n",
        "for class_i in range(10):\n",
        "    os.mkdir(folder_name+\"/\"+str(class_i))\n",
        "    for path_dir, dirnames, filenames in os.walk('imagenet_dataset/'+str(class_i)):\n",
        "        coeffs_list=[]\n",
        "        segments = \"\" #Store segments to calculate LnO\n",
        "        num_superpixels = 0 #Store number of superpixels\n",
        "        image = 0 #Store image\n",
        "\n",
        "        for file in filenames:\n",
        "            img_path = path_dir+\"/\"+file\n",
        "            img = get_image(img_path)\n",
        "            plt.imshow(img)\n",
        "            plt.close()\n",
        "\n",
        "            image = np.array(pill_transf(img))\n",
        "\n",
        "            os.mkdir(folder_name+\"/\"+str(class_i)+\"/data\")\n",
        "            os.mkdir(folder_name+\"/\"+str(class_i)+\"/labels\")\n",
        "\n",
        "            for i in range(runs):  \n",
        "                os.mkdir(folder_name+\"/\"+str(class_i)+\"/data/\"+\"run_\"+str(i))\n",
        "                os.mkdir(folder_name+\"/\"+str(class_i)+\"/labels/\"+\"run_\"+str(i))  \n",
        "\n",
        "                print(\"RUN: \", i+1)\n",
        "\n",
        "                coeff_list = []\n",
        "\n",
        "                for p in perturbations_num:\n",
        "                    num_perturb = p\n",
        "\n",
        "                    data_fixed = open(data_labels_folder+\"/\"+str(class_i)+\"/data/\"+\"run_\"+str(i)+\"/\"+str(p)+\".txt\", \"r\")\n",
        "                    data_fixed.readline()\n",
        "                    data_fixed = np.array(ast.literal_eval(data_fixed.read()))\n",
        "                    print(data_fixed.shape)\n",
        "\n",
        "                    labels_fixed = open(data_labels_folder+\"/\"+str(class_i)+\"/labels/\"+\"run_\"+str(i)+\"/\"+str(p)+\".txt\", \"r\")\n",
        "                    labels_fixed.readline()\n",
        "                    labels_fixed = np.array(ast.literal_eval(labels_fixed.read()))\n",
        "                    print(labels_fixed.shape)\n",
        "\n",
        "                    predictions = []\n",
        "\n",
        "                    explanation, segments, label, data, labels = explainer.explain_instance(image, \n",
        "                                                            batch_predict, data_fixed, labels_fixed,\n",
        "                                                            class_i, \n",
        "                                                            top_labels=1, \n",
        "                                                            hide_color=0, \n",
        "                                                            num_samples=num_perturb) # number of images that will be sent to classification function\n",
        "\n",
        "                    print(\"Yee: \", label)\n",
        "                    fX= open(folder_name+\"/\"+str(class_i)+\"/data/\"+\"run_\"+str(i)+\"/\"+str(p)+\".txt\",\"w+\")\n",
        "                    fX.write(\"Class: \"+str(class_i))\n",
        "                    fX.write(\"\\n\")\n",
        "                    data_list_all = []\n",
        "\n",
        "                    for pert_index in range(len(data)):\n",
        "                      data_list = list(data[pert_index])\n",
        "                      data_list_all.append(data_list)\n",
        "\n",
        "\n",
        "                    fX.write(str(data_list_all))\n",
        "                    fX.write(\"\\n\\n\")\n",
        "                    fX.close()\n",
        "\n",
        "                    fY= open(folder_name+\"/\"+str(class_i)+\"/labels/\"+\"run_\"+str(i)+\"/\"+str(p)+\".txt\",\"w+\")\n",
        "                    fY.write(\"Class: \"+str(class_i))\n",
        "                    fY.write(\"\\n\")\n",
        "\n",
        "                    # print(\"Labels Shape: \", labels.shape)\n",
        "                    # print(\"Labels: \", labels[:, class_i])\n",
        "\n",
        "                    labels_list = list(labels)\n",
        "                    fY.write(str(labels_list))\n",
        "                    fY.write(\"\\n\\n\")\n",
        "                    fY.close()\n",
        "\n",
        "                    coeff = [None] * (np.unique(segments).shape[0])\n",
        "\n",
        "                    print(\"Number of superpixels: \", np.unique(segments).shape[0])\n",
        "                    num_superpixels = np.unique(segments).shape[0]\n",
        "\n",
        "                    for exp_tuple in explanation.local_exp[label]:\n",
        "                      coeff[exp_tuple[0]] = exp_tuple[1]\n",
        "\n",
        "                    # print(\"Code Coeff: \", np.array(coeff))\n",
        "                    # print(\"Code Coeff Shape: \", np.array(coeff).shape)\n",
        "\n",
        "                    #Normalize coeff_list\n",
        "                    coeff_norm = [(float(i)-min(coeff))/(max(coeff)-min(coeff)) for i in coeff]\n",
        "                    # print(\"Normalized: \", np.array(coeff_norm))\n",
        "                    coeff_list.append(coeff_norm)\n",
        "\n",
        "                coeffs_list.append(coeff_list)\n",
        "\n",
        "#coeffs_list contains coefficients of all simpler models trained on all the perturbations_num x 10 RUNS\n",
        "            # print(\"Coeff list shape: \", np.array(coeffs_list).shape)\n",
        "            # print(np.array(coeffs_list))\n",
        "\n",
        "            plt.imshow(skimage.segmentation.mark_boundaries(image, segments))\n",
        "            plt.axis('off')\n",
        "            plt.savefig(folder_name+\"/\"+str(class_i)+'/seg_image.png', bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "            plt.imshow(image)\n",
        "            plt.axis('off')\n",
        "            plt.savefig(folder_name+\"/\"+str(class_i)+'/org_image.png', bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "            fc= open(folder_name+\"/\"+str(class_i)+\"/coeffs_list.txt\",\"w+\")\n",
        "            fc.write(\"Class: \"+str(class_i))\n",
        "            fc.write(\"\\n\")\n",
        "            fc.write(str(coeffs_list))\n",
        "            fc.write(\"\\n\\n\")\n",
        "            fc.close()\n",
        "                \n",
        "            probability_list_run = []\n",
        "            probability_list_pert = []\n",
        "            for i in range(runs): #Runs\n",
        "                probability_list_pert=[]\n",
        "\n",
        "                for j in range(len(perturbations_num)): #Perturbations\n",
        "                    probability_list_n=[]\n",
        "\n",
        "                    for k in range(0, len(coeffs_list[i][j])+1): #Coefficients\n",
        "                        num_top_features = k\n",
        "                        if num_top_features == 0:\n",
        "                            top_features = []\n",
        "                        else:\n",
        "                            top_features = np.argsort(coeffs_list[i][j])[-num_top_features:] \n",
        "\n",
        "\n",
        "                        mask_exp = np.ones(num_superpixels) \n",
        "                        mask_exp[top_features]= False\n",
        "\n",
        "                        image = np.array(pill_transf(img))\n",
        "                        fudged_image = image.copy()\n",
        "                        fudged_image[:] = 0\n",
        "                        # for x in np.unique(segments):\n",
        "                        #   fudged_image[segments == x] = (\n",
        "                        #     np.mean(image[segments == x][:, 0]),\n",
        "                        #     np.mean(image[segments == x][:, 1]),\n",
        "                        #     np.mean(image[segments == x][:, 2]))\n",
        "\n",
        "                        temp = copy.deepcopy(image)\n",
        "                        zeros = np.where(mask_exp == 0)[0]\n",
        "                        mask = np.zeros(segments.shape).astype(bool)\n",
        "\n",
        "                        for z in zeros:\n",
        "                            mask[segments == z] = True\n",
        "                        temp[mask] = fudged_image[mask]\n",
        "\n",
        "                        # plt.imshow(temp)\n",
        "                        # plt.show()\n",
        "                        # plt.close()\n",
        "\n",
        "                        imgs = []\n",
        "                        imgs.append(temp)\n",
        "\n",
        "                        preds = batch_predict(np.array(imgs))\n",
        "                        # print(\"Prediction Shape: \", preds.shape)\n",
        "                        # print(\"Prediction[0] Shape: \", preds[0].shape)\n",
        "                        # print(\"Prediction: \", preds)\n",
        "\n",
        "                        probability_list_n.append(preds[0][class_i])\n",
        "\n",
        "                    probability_list_pert.append(probability_list_n)\n",
        "\n",
        "                #probability_list_run structure (Run, Perturbation, LnO (Superpixels + 1))\n",
        "                probability_list_run.append(probability_list_pert)\n",
        "                # print(np.array(probability_list_run).shape)\n",
        "                # print(np.array(probability_list_run))\n",
        "\n",
        "\n",
        "            f= open(folder_name+\"/\"+str(class_i)+\"/LnO.txt\",\"w+\")\n",
        "            for run in range(runs):\n",
        "                f.write(\"RUN: %d\\n\\n\" % run)\n",
        "                for pert in range(len(perturbations_num)):\n",
        "                    f.write(\"PERTURBATION: %d\\n\" % perturbations_num[pert])\n",
        "                    f.write(str(probability_list_run[run][pert]))\n",
        "                    f.write(\"\\n\")\n",
        "            f.close()\n",
        "\n",
        "\n",
        "            n_list = [n for n in range(num_superpixels+1)]\n",
        "            _list = []\n",
        "            _list1 = []\n",
        "\n",
        "            for pert in range(len(perturbations_num)):\n",
        "                _list=[]\n",
        "                for run in range(runs):\n",
        "                    _list.append(probability_list_run[run][pert])\n",
        "                _list1.append(_list)\n",
        "            # print(np.array(_list1).shape)\n",
        "\n",
        "            os.mkdir(folder_name+\"/\"+str(class_i)+'/LnO')\n",
        "            for pert in range(len(perturbations_num)):\n",
        "                os.mkdir(folder_name+\"/\"+str(class_i)+'/LnO/'+str(perturbations_num[pert]))\n",
        "                for run in range(runs):\n",
        "                    plt.xlabel(\"n\")\n",
        "                    plt.ylabel(\"LnO Accuracy\")\n",
        "                    plt.plot(n_list, _list1[pert][run])\n",
        "                    plt.savefig(folder_name+\"/\"+str(class_i)+'/LnO/'+str(perturbations_num[pert])+\"/run_\"+str(run)+'.png', bbox_inches='tight')\n",
        "                    plt.close()\n",
        "\n",
        "            for pert in range(len(perturbations_num)):\n",
        "                for run in range(runs):\n",
        "                    plt.xlabel(\"n\")\n",
        "                    plt.ylabel(\"LnO Accuracy\")\n",
        "                    plt.plot(n_list, _list1[pert][run])\n",
        "                plt.savefig(folder_name+\"/\"+str(class_i)+'/LnO/'+str(perturbations_num[pert])+\"/all_runs.png\", bbox_inches='tight')\n",
        "                plt.close()\n",
        "\n",
        "\n",
        "            for run in range(runs):\n",
        "                os.mkdir(folder_name+\"/\"+str(class_i)+\"/\"+str(run))\n",
        "                os.mkdir(folder_name+\"/\"+str(class_i)+\"/\"+str(run)+\"/heatmaps\")\n",
        "                for pert in range(len(perturbations_num)):\n",
        "                    heat_img = heatmap_image(image,coeffs_list[run][pert],segments)\n",
        "                    plt.imshow(heat_img)\n",
        "                    plt.axis('off')\n",
        "                    plt.savefig(folder_name+\"/\"+str(class_i)+\"/\"+str(run)+\"/heatmaps/\"+str(perturbations_num[pert])+\".png\", bbox_inches='tight')\n",
        "                    plt.close()\n",
        "\n",
        "            l1=[]\n",
        "            l2=[]\n",
        "            l3=[]\n",
        "\n",
        "            for pert in range(len(perturbations_num)): #Pick perturbation number\n",
        "                for n in range(len(probability_list_run[0][0])-1): #Coefficients\n",
        "                    for run in range(runs): #runs\n",
        "                        l1.append(coeffs_list[run][pert][n]) #List of kth coeff of all runs for perturbation j \n",
        "                    l2.append(l1) #List all coeffs for perturbation pert  \n",
        "                    l1=[]\n",
        "                l3.append(l2) #List of all perturbations \n",
        "                l2 = []\n",
        "\n",
        "            # l2 is structured like (per pert) [ [1st coeff for all runs], [2nd coeff for all runs], [3rd coeff for all runs] ... ]\n",
        "            # l3 is structured like [ [1st pert l2], [2nd pert l2], [3rd pert l2] ... ]\n",
        "\n",
        "            total_var_l = []\n",
        "            total_mean_l = []\n",
        "            f= open(folder_name+\"/\"+str(class_i)+\"/pert_var.txt\",\"w+\")\n",
        "            for pert in range(len(perturbations_num)):\n",
        "                print(\"Perturbation: \", perturbations_num[pert],\"\\n\")\n",
        "                f.write(\"Perturbation: \" + str(perturbations_num[pert]) +\"\\n\")\n",
        "                total_var = 0\n",
        "                total_mean = 0\n",
        "                for n in range(len(l3[pert])): #go through all coefficients\n",
        "                    total_var += np.var(l3[pert][n])\n",
        "                    total_mean += np.mean(l3[pert][n])\n",
        "                    for j in range(n+1, len(l3[pert])):\n",
        "                        total_var += 2 * np.cov(l3[pert][n], l3[pert][j], ddof=0)[0][1] #Extract covariance value from covariance matrix\n",
        "                print(\"Mean: \", total_mean)\n",
        "                print(\"Var: \",total_var)\n",
        "                f.write(\"Mean: \"+str(total_mean)+\"\\n\")\n",
        "                f.write(\"Var: \"+str(total_var)+\"\\n\")\n",
        "                total_var_l.append(total_var)\n",
        "            f.close()\n",
        "\n",
        "            plt.xlabel(\"Perturbations\")\n",
        "            plt.ylabel(\"Variance\")\n",
        "            plt.plot(perturbations_num, total_var_l)\n",
        "            plt.savefig(folder_name+\"/\"+str(class_i)+'/pert_var.png', bbox_inches='tight')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ZmNvUcxlItyG",
        "outputId": "2da3a854-9a75-4dc6-c0ce-63b4eb1c8d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-244a572e7da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mpill_transf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pil_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mpreprocess_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_preprocess_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-244a572e7da3>\u001b[0m in \u001b[0;36mget_pil_transform\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_pil_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     transf = transforms.Compose([\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCenterCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GvMMjIxyk1Gd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
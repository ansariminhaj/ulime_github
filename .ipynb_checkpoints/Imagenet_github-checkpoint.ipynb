{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WnSUa5ooH_1L",
    "outputId": "8b404a26-11e4-4f2a-b482-267369fbd38c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ulime_github' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "#Please set Colaboratory Runtime to GPU before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clone this repository to access \n",
    "#i.   Base code of ULIME, L2 LIME and Cosine LIME.\n",
    "#ii.  Dataset and preset perturbations + labels to test all three LIME variants on\n",
    "#iii. requirements.txt for installing necessary packages\n",
    "!git clone https://github.com/ansariminhaj/ulime_github.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfd52bc2kmvj"
   },
   "outputs": [],
   "source": [
    "#Install all packages\n",
    "!pip install -r ulime_github/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-SlVsNYncO3"
   },
   "outputs": [],
   "source": [
    "#Uzip folder containig base code of ULIME, L2 LIME and Cosine LIME.\n",
    "!unzip ulime_github/lime_lib_fixed.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iMmXLjBzkiYV"
   },
   "outputs": [],
   "source": [
    "#Import all required packages\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import skimage.io \n",
    "import skimage.segmentation\n",
    "import copy\n",
    "import os\n",
    "from PIL import Image\n",
    "import ast\n",
    "from itertools import product\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "MW44fjCHIJUp",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a9e4ae73-2e1a-4d09-ea76-2bcf9814271f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Black box model to explain\n",
    "#We use the ImageNet pretrained inception_v3 model in this tutorial\n",
    "model = torchvision.models.inception_v3(pretrained=True) #Load pretrained model\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "p2rBI6GpILLH"
   },
   "outputs": [],
   "source": [
    "from lime_lib_fixed.lime_org_U.lime import lime_image #(Use a fresh kernel before importing so that cache is empty)\n",
    "#from lime_lib_fixed.lime_org_l2.lime import lime_image #(Use a fresh kernel before importing so that cache is empty)\n",
    "#from lime_lib_fixed.lime_org_cosine.lime import lime_image #(Use a fresh kernel before importing so that cache is empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZmNvUcxlItyG",
    "outputId": "834f53cd-76fe-4e30-cde2-c3aade4c0814"
   },
   "outputs": [],
   "source": [
    "#Heatmaps are used to visualize the LIME explanations.\n",
    "#We use the Viridis Colormap for visualization\n",
    "def heatmap_image(img,c_list,segments):\n",
    "    num_superpixels = np.unique(segments).shape[0]\n",
    "    mask = np.zeros(segments.shape)\n",
    "    for i in range(num_superpixels):\n",
    "        mask[segments == i] = c_list[i] \n",
    "    return mask\n",
    "\n",
    "#This functions imports an image and converts it to RGB\n",
    "def get_image(path):\n",
    "  with open(os.path.abspath(path), 'rb') as f:\n",
    "      with Image.open(f) as img:\n",
    "          return img.convert('RGB') \n",
    "        \n",
    "#Resize and take the center part of image to what our model expects\n",
    "# def get_input_transform():\n",
    "#     normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                     std=[0.229, 0.224, 0.225])       \n",
    "#     transf = transforms.Compose([\n",
    "#         transforms.Resize((256, 256)),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize\n",
    "#     ])    \n",
    "\n",
    "#     return transf\n",
    "\n",
    "def get_input_tensors(img):\n",
    "    transf = get_input_transform()\n",
    "    # unsqeeze converts single image to batch of 1\n",
    "    return transf(img).unsqueeze(0)\n",
    "\n",
    "def get_pil_transform(): \n",
    "    transf = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224)\n",
    "    ])    \n",
    "\n",
    "    return transf\n",
    "\n",
    "def get_preprocess_transform():\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])     \n",
    "    transf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])    \n",
    "\n",
    "    return transf    \n",
    "\n",
    "pill_transf = get_pil_transform()\n",
    "preprocess_transform = get_preprocess_transform()\n",
    "\n",
    "#This function is used to feed input to the black box model \n",
    "#The purpose is to obtain class probabilities for perturbed image\n",
    "#These probabilities are used as labels along with the perturbations to train a linear model\n",
    "def batch_predict(images):\n",
    "    model.eval()\n",
    "    batch = torch.stack(tuple(preprocess_transform(i) for i in images), dim=0)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    logits = model(batch)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    return probs.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOBAL PARAMETERS\n",
    "\n",
    "#List of perturbation quantities P\n",
    "perturbations_num = [10, 50, 100, 200, 300, 500, 700, 1000, 1500, 2000, 2500, 3000]\n",
    "\n",
    "#This folder contains fixed perturbations (data.txt) + associated labels (labels.txt) for the first 10 ImageNet classes.\n",
    "data_labels_folder = \"ulime_github/pert_labels\"\n",
    "\n",
    "#Folder to store explanations and metrics (LnO, heatmaps, Combined Variance)\n",
    "folder_name = \"imagenet_ulime\"\n",
    "os.mkdir(folder_name)\n",
    "\n",
    "#Number of times LIME runs per image\n",
    "runs = 10\n",
    "\n",
    "#Number of images that this tutorial needs to run on\n",
    "#We have provided 10 images for the tutorial, please contact us at minhaj3737@gmail.com if you need the entire dataset.\n",
    "#The 10 images are from ImageNet classes 0-9, 1 image from each class\n",
    "number_images = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lime_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2d49835540aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlime_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLimeImageExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_selection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclass_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#Make a folder for each image that is being explained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lime_image' is not defined"
     ]
    }
   ],
   "source": [
    "explainer = lime_image.LimeImageExplainer(feature_selection='none')\n",
    "\n",
    "for class_i in range(number_images):\n",
    "    \n",
    "    #Make a folder for each image that is being explained\n",
    "    os.mkdir(folder_name+\"/\"+str(class_i))\n",
    "    \n",
    "    #Walk through all images per class folder. In this tutorial, we only have one image per class folder\n",
    "    for path_dir, dirnames, filenames in os.walk('ulime_github/imagenet_10images/'+str(class_i)):\n",
    "        coeffs_list=[]\n",
    "        segments = \"\" #Stores superpixel segments to calculate LnO\n",
    "        num_superpixels = 0 #Stores number of superpixels\n",
    "        image = 0 #Stores the image being explained\n",
    "        \n",
    "        #This returns the image file in the folder\n",
    "        for file in filenames:\n",
    "            img_path = path_dir+\"/\"+file\n",
    "            \n",
    "            #Convert image to RGB\n",
    "            img = get_image(img_path)\n",
    "            plt.imshow(img)\n",
    "            plt.close()\n",
    "            \n",
    "            #Tranform image (Only resize). Normalization will be applied in the batch_predict function\n",
    "            #This is because the segmentation algorithm needed by LIME should only be applied on the actual image\n",
    "            #Not a normalized image. The normalization is only needed for the black box model, therefore,\n",
    "            #it has been exclusively kept in the black box prediction function.\n",
    "            image = np.array(pill_transf(img))\n",
    "            \n",
    "            #Create folder for the predefined perturbations (data) and associated labels being used.\n",
    "            #This is useful when you want to create your own set of random perturbations and labels.\n",
    "            #You run one LIME variant once, store the perturbations and labels, and use those for\n",
    "            #other LIME variants so that the comparison is fair.\n",
    "            #Modifications in the code needed to create your own set of perturbations given in the\n",
    "            #last code block.\n",
    "            os.mkdir(folder_name+\"/\"+str(class_i)+\"/data\")\n",
    "            os.mkdir(folder_name+\"/\"+str(class_i)+\"/labels\")\n",
    "            \n",
    "            #Run 'r' times per image. \n",
    "            for i in range(runs): \n",
    "                \n",
    "                #Create a perturbation and labels subfolder for each run.\n",
    "                os.mkdir(folder_name+\"/\"+str(class_i)+\"/data/\"+\"run_\"+str(i))\n",
    "                os.mkdir(folder_name+\"/\"+str(class_i)+\"/labels/\"+\"run_\"+str(i))  \n",
    "\n",
    "                print(\"RUN: \", i+1)\n",
    "                \n",
    "                #Coeff_list stores the coefficients of the linear model for each LIME explanation\n",
    "                coeff_list = []\n",
    "                \n",
    "                #Run through all the perturbation quantities defined in perturbations_num\n",
    "                for p in perturbations_num:\n",
    "                    num_perturb = p\n",
    "                    \n",
    "                    #Extract the fixed perturbations\n",
    "                    data_fixed = open(data_labels_folder+\"/\"+str(class_i)+\"/data/\"+\"run_\"+str(i)+\"/\"+str(p)+\".txt\", \"r\")\n",
    "                    data_fixed.readline()\n",
    "                    data_fixed = np.array(ast.literal_eval(data_fixed.read()))\n",
    "                    print(\"Perturbations shape: \", data_fixed.shape)\n",
    "                    \n",
    "                    #Extract the associated labels for the fixed perturbations\n",
    "                    labels_fixed = open(data_labels_folder+\"/\"+str(class_i)+\"/labels/\"+\"run_\"+str(i)+\"/\"+str(p)+\".txt\", \"r\")\n",
    "                    labels_fixed.readline()\n",
    "                    labels_fixed = np.array(ast.literal_eval(labels_fixed.read()))\n",
    "                    print(\"Labels shape: \", labels_fixed.shape)\n",
    "\n",
    "                    predictions = []\n",
    "                    \n",
    "                    #Explain the image with the fixed perturbations and labels\n",
    "                    #This is where the linear model is trained \n",
    "                    #The output is the:\n",
    "                    #i. explanation: Coefficients of the linear model\n",
    "                    #ii. segments: Superpixels. Used to view the explanation heatmaps\n",
    "                    #iii. label: The label we gave LIME to generate an explanation for the image\n",
    "                    #iv. data: Fixed perturbations we gave as input to LIME\n",
    "                    #v. labels: Fixed labels we gave as input to LIME\n",
    "                    explanation, segments, label, data, labels = explainer.explain_instance(image, \n",
    "                                                            batch_predict, data_fixed, labels_fixed,\n",
    "                                                            class_i, \n",
    "                                                            top_labels=1, \n",
    "                                                            hide_color=0, \n",
    "                                                            num_samples=num_perturb) # number of images that will be sent to classification function\n",
    "                    \n",
    "                    #Write purterbations in the perturbations folder\n",
    "                    fX= open(folder_name+\"/\"+str(class_i)+\"/data/\"+\"run_\"+str(i)+\"/\"+str(p)+\".txt\",\"w+\")\n",
    "                    fX.write(\"Class: \"+str(class_i))\n",
    "                    fX.write(\"\\n\")\n",
    "                    data_list_all = []\n",
    "                    \n",
    "                    for pert_index in range(len(data)):\n",
    "                      data_list = list(data[pert_index])\n",
    "                      data_list_all.append(data_list)\n",
    "\n",
    "                    fX.write(str(data_list_all))\n",
    "                    fX.write(\"\\n\\n\")\n",
    "                    fX.close()\n",
    "                    \n",
    "                    #Write labels in the perturbations folder\n",
    "                    fY= open(folder_name+\"/\"+str(class_i)+\"/labels/\"+\"run_\"+str(i)+\"/\"+str(p)+\".txt\",\"w+\")\n",
    "                    fY.write(\"Class: \"+str(class_i))\n",
    "                    fY.write(\"\\n\")\n",
    "\n",
    "                    labels_list = list(labels)\n",
    "                    fY.write(str(labels_list))\n",
    "                    fY.write(\"\\n\\n\")\n",
    "                    fY.close()\n",
    "\n",
    "                    coeff = [None] * (np.unique(segments).shape[0])\n",
    "\n",
    "                    print(\"Number of superpixels: \", np.unique(segments).shape[0])\n",
    "                    num_superpixels = np.unique(segments).shape[0]\n",
    "                    \n",
    "                    #Save the linear model coefficients in the coeff list\n",
    "                    for exp_tuple in explanation.local_exp[label]:\n",
    "                      coeff[exp_tuple[0]] = exp_tuple[1]\n",
    "\n",
    "                    #Normalize coeff list and store normalized coefficients in another list coeff_list\n",
    "                    coeff_norm = [(float(i)-min(coeff))/(max(coeff)-min(coeff)) for i in coeff]\n",
    "                    coeff_list.append(coeff_norm)\n",
    "                    \n",
    "                #coeffs_list contains coefficients of all the linear models trained on all the perturbations\n",
    "                coeffs_list.append(coeff_list)\n",
    "\n",
    "            \n",
    "            #Show the superpixilized image and save it \n",
    "            plt.imshow(skimage.segmentation.mark_boundaries(image, segments))\n",
    "            plt.axis('off')\n",
    "            plt.savefig(folder_name+\"/\"+str(class_i)+'/seg_image.png', bbox_inches='tight')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            #Show the original image and save it \n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "            plt.savefig(folder_name+\"/\"+str(class_i)+'/org_image.png', bbox_inches='tight')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            #Save all coefficients in a text file in case they need to be accessed in the future.\n",
    "            fc= open(folder_name+\"/\"+str(class_i)+\"/coeffs_list.txt\",\"w+\")\n",
    "            fc.write(\"Class: \"+str(class_i))\n",
    "            fc.write(\"\\n\")\n",
    "            fc.write(str(coeffs_list))\n",
    "            fc.write(\"\\n\\n\")\n",
    "            fc.close()\n",
    "            \n",
    "            ### This section is for creating LnO's values ###\n",
    "            #probability list pert stores all probabilities of a particular class\n",
    "            #as the superpixels are removed from most important to least important\n",
    "            #for all linear models trained in the previous step\n",
    "            probability_list_run = []\n",
    "            probability_list_pert = []\n",
    "            for i in range(runs): #Runs\n",
    "                probability_list_pert=[]\n",
    "\n",
    "                for j in range(len(perturbations_num)): #Perturbations\n",
    "                    probability_list_n=[]\n",
    "                    \n",
    "                    #k goes from 1 to number of coefficients + 1 (since we start from the whole image)\n",
    "                    #Each coefficient is associated with a superpixel. The magnitude of the coefficient\n",
    "                    #specifies the importance of the superpixel in the explanation.\n",
    "                    #We do an argsort and remove superpixels from most to least important.\n",
    "                    for k in range(0, len(coeffs_list[i][j])+1): #Coefficients\n",
    "                        num_top_features = k\n",
    "                        if num_top_features == 0:\n",
    "                            top_features = []\n",
    "                        else:\n",
    "                            top_features = np.argsort(coeffs_list[i][j])[-num_top_features:] \n",
    "\n",
    "\n",
    "                        mask_exp = np.ones(num_superpixels) \n",
    "                        mask_exp[top_features]= False\n",
    "\n",
    "                        image = np.array(pill_transf(img))\n",
    "                        fudged_image = image.copy()\n",
    "                        fudged_image[:] = 0\n",
    "\n",
    "                        temp = copy.deepcopy(image)\n",
    "                        zeros = np.where(mask_exp == 0)[0]\n",
    "                        mask = np.zeros(segments.shape).astype(bool)\n",
    "\n",
    "                        for z in zeros:\n",
    "                            mask[segments == z] = True\n",
    "                        temp[mask] = fudged_image[mask]\n",
    "\n",
    "                        imgs = []\n",
    "                        imgs.append(temp)\n",
    "                        \n",
    "                        #Each time we remove a superpixel, we note down the black box classification value\n",
    "                        preds = batch_predict(np.array(imgs))\n",
    "\n",
    "                        probability_list_n.append(preds[0][class_i])\n",
    "\n",
    "                    probability_list_pert.append(probability_list_n)\n",
    "\n",
    "                #probability_list_run is structured as (Run, Perturbation, LnO (Superpixels + 1))\n",
    "                probability_list_run.append(probability_list_pert)\n",
    "\n",
    "            #Save the LnO's in a text file\n",
    "            f= open(folder_name+\"/\"+str(class_i)+\"/LnO.txt\",\"w+\")\n",
    "            for run in range(runs):\n",
    "                f.write(\"RUN: %d\\n\\n\" % run)\n",
    "                for pert in range(len(perturbations_num)):\n",
    "                    f.write(\"PERTURBATION: %d\\n\" % perturbations_num[pert])\n",
    "                    f.write(str(probability_list_run[run][pert]))\n",
    "                    f.write(\"\\n\")\n",
    "            f.close()\n",
    "\n",
    "            ### This section is for graphing the LnO's values ###\n",
    "            n_list = [n for n in range(num_superpixels+1)]\n",
    "            _list = []\n",
    "            _list1 = []\n",
    "\n",
    "            for pert in range(len(perturbations_num)):\n",
    "                _list=[]\n",
    "                for run in range(runs):\n",
    "                    _list.append(probability_list_run[run][pert])\n",
    "                _list1.append(_list)\n",
    "            \n",
    "            #Graph LnO for each run and perturbation individually\n",
    "            os.mkdir(folder_name+\"/\"+str(class_i)+'/LnO')\n",
    "            for pert in range(len(perturbations_num)):\n",
    "                os.mkdir(folder_name+\"/\"+str(class_i)+'/LnO/'+str(perturbations_num[pert]))\n",
    "                for run in range(runs):\n",
    "                    plt.xlabel(\"n\")\n",
    "                    plt.ylabel(\"LnO Accuracy\")\n",
    "                    plt.plot(n_list, _list1[pert][run])\n",
    "                    plt.savefig(folder_name+\"/\"+str(class_i)+'/LnO/'+str(perturbations_num[pert])+\"/run_\"+str(run)+'.png', bbox_inches='tight')\n",
    "                    plt.close()\n",
    "            \n",
    "            #Graph all 10 runs for a perturbation in a single figure\n",
    "            for pert in range(len(perturbations_num)):\n",
    "                for run in range(runs):\n",
    "                    plt.xlabel(\"n\")\n",
    "                    plt.ylabel(\"LnO Accuracy\")\n",
    "                    plt.plot(n_list, _list1[pert][run])\n",
    "                plt.savefig(folder_name+\"/\"+str(class_i)+'/LnO/'+str(perturbations_num[pert])+\"/all_runs.png\", bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "            #Plot heatmaps of each explanation based on the normalized coefficient values\n",
    "            for run in range(runs):\n",
    "                os.mkdir(folder_name+\"/\"+str(class_i)+\"/\"+str(run))\n",
    "                os.mkdir(folder_name+\"/\"+str(class_i)+\"/\"+str(run)+\"/heatmaps\")\n",
    "                for pert in range(len(perturbations_num)):\n",
    "                    heat_img = heatmap_image(image,coeffs_list[run][pert],segments)\n",
    "                    plt.imshow(heat_img)\n",
    "                    plt.axis('off')\n",
    "                    plt.savefig(folder_name+\"/\"+str(class_i)+\"/\"+str(run)+\"/heatmaps/\"+str(perturbations_num[pert])+\".png\", bbox_inches='tight')\n",
    "                    plt.close()\n",
    "            \n",
    "            ### This section is for plotting the combined variance ###\n",
    "            #We do this for each perturbation. We find how much the combined variance exists across the 10 runs\n",
    "            #per perturbation\n",
    "            l1=[]\n",
    "            l2=[]\n",
    "            l3=[]\n",
    "\n",
    "            for pert in range(len(perturbations_num)): #Pick perturbation number\n",
    "                for n in range(len(probability_list_run[0][0])-1): #Coefficients\n",
    "                    for run in range(runs): #runs\n",
    "                        l1.append(coeffs_list[run][pert][n]) #List of kth coeff of all runs for perturbation j \n",
    "                    l2.append(l1) #List all coeffs for perturbation pert  \n",
    "                    l1=[]\n",
    "                l3.append(l2) #List of all perturbations \n",
    "                l2 = []\n",
    "\n",
    "            # l2 is structured like (per pert) [ [1st coeff for all runs], [2nd coeff for all runs], [3rd coeff for all runs] ... ]\n",
    "            # l3 is structured like [ [1st pert l2], [2nd pert l2], [3rd pert l2] ... ]\n",
    "\n",
    "            total_var_l = []\n",
    "            total_mean_l = []\n",
    "            f= open(folder_name+\"/\"+str(class_i)+\"/pert_var.txt\",\"w+\")\n",
    "            for pert in range(len(perturbations_num)):\n",
    "                print(\"Perturbation: \", perturbations_num[pert],\"\\n\")\n",
    "                f.write(\"Perturbation: \" + str(perturbations_num[pert]) +\"\\n\")\n",
    "                total_var = 0\n",
    "                total_mean = 0\n",
    "                for n in range(len(l3[pert])): #go through all coefficients\n",
    "                    total_var += np.var(l3[pert][n])\n",
    "                    total_mean += np.mean(l3[pert][n])\n",
    "                    for j in range(n+1, len(l3[pert])):\n",
    "                        total_var += 2 * np.cov(l3[pert][n], l3[pert][j], ddof=0)[0][1] #Extract covariance value from covariance matrix\n",
    "                print(\"Mean: \", total_mean)\n",
    "                print(\"Var: \",total_var)\n",
    "                f.write(\"Mean: \"+str(total_mean)+\"\\n\")\n",
    "                f.write(\"Var: \"+str(total_var)+\"\\n\")\n",
    "                total_var_l.append(total_var)\n",
    "            f.close()\n",
    "            \n",
    "            #Plot the combined variance graph.\n",
    "            plt.xlabel(\"Perturbations\")\n",
    "            plt.ylabel(\"Variance\")\n",
    "            plt.plot(perturbations_num, total_var_l)\n",
    "            plt.savefig(folder_name+\"/\"+str(class_i)+'/pert_var.png', bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For generating your own perturbations and labels, follow the steps below: \n",
    "\n",
    "#UNCOMMENT these lines in lime_image.py: \n",
    "#201 data, labels = self.data_labels(image, fudged_image, segments,\n",
    "#202                                 classifier_fn, num_samples,\n",
    "#203                                 batch_size=batch_size,\n",
    "#204                                 progress_bar=progress_bar)\n",
    "\n",
    "#COMMENT these lines in lime_image.py:\n",
    "#206 data = data_fixed\n",
    "#207 labels = labels_fixed\n",
    "\n",
    "#UNCOMMENT #[:, label] in line 184 (labels_column = neighborhood_labels#[:, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvMMjIxyk1Gd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Imagenet_github.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
